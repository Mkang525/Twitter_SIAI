{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWelcome to the Wesley Initiation File! \n",
      "\n",
      "        \n",
      "The Wesley Initiation File consists of multiple functions to help us with our tasks. \n",
      "I am loading the following functions:\n",
      "\tfind_file(pathway)\n",
      "\twalk_directory(directory)\n",
      "\twalk_directory_verbose(directory)\n",
      "\tinitialize_data_log()\n",
      "\tinitialize_syn_log()\n",
      "\tinitialize_url_log()\n",
      "\tpdf_to_txt(path)\n",
      "\ttxt_to_txt(path)\n",
      "\tdocx_to_txt(path)\n",
      "\trtf_to_txt(path)\n",
      "\tto_string(text)\n",
      "\tto_bytes(text)\n",
      "\tclean_the_text(text, remove_numbers=False)\n",
      "\tpos_tag(text)\n",
      "\tcount_unique_words(string)\n",
      "\tcount_words(text)\n",
      "\tcount_word_frequency(text)\n",
      "\tdetermine_pdf_encoding(file)\n",
      "\tngram_list(text, n_gram_size)\n",
      "\tfind_keywords(text)\n",
      "\ttokenize_by_words(text)\n",
      "\ttokenize_by_words2(text)\n",
      "\tsplit_into_sentences(text)\n",
      "\tsimple_tokenize_by_sentences(text)\n",
      "\ttokenize_by_paragraphs(text)\n",
      "\tremove_stopwords(text, is_lower_case=False)\n",
      "\tsimple_stemmer(text)\n",
      "\tlemmatize_text(text)\n",
      "\tsingle_word_search(search_word)\n",
      "\taccessed_created_modified(file)\n",
      "\tplot_top_ngrams_barchart(text, n=2)\n",
      "\tplot_named_entity_barchart(text)\n",
      "\tpull_urls(text)\n",
      "\tfind_synonyms(search_term)\n",
      "\tget_synonyms(search_term)\n",
      "\tcosine_similarity(string_1, string_2)\n",
      "\tlevenshtein_distance(string_1, string_2)\n",
      "\ttext_summarization(text)\n",
      "\tshow_wordcloud(data, title = None)\n",
      "\ttfidf_string_similarity_test(correct_string,test_string)\n"
     ]
    }
   ],
   "source": [
    "%run lib/__wesley_init_verbose__.py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>52383</th>\n",
       "      <th>58440</th>\n",
       "      <th>39635</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>809810597734924288</td>\n",
       "      <td>596073234635890690</td>\n",
       "      <td>967548575763673088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversation_id</th>\n",
       "      <td>809810597734924288</td>\n",
       "      <td>592026311796850690</td>\n",
       "      <td>967521441863225345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_at</th>\n",
       "      <td>2016-12-16 12:21:06 EST</td>\n",
       "      <td>2015-05-06 18:05:08 EDT</td>\n",
       "      <td>2018-02-24 18:55:31 EST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>2015-05-06</td>\n",
       "      <td>2018-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>12:21:06</td>\n",
       "      <td>18:05:08</td>\n",
       "      <td>18:55:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timezone</th>\n",
       "      <td>-500</td>\n",
       "      <td>-500</td>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>776947029276758016</td>\n",
       "      <td>2931195472</td>\n",
       "      <td>822444348977463296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <td>_dmin_</td>\n",
       "      <td>airspray6179</td>\n",
       "      <td>poetwoagun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>Destiny Minker</td>\n",
       "      <td>s</td>\n",
       "      <td>poetWOAgun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>Y'all wanna freak about a shooting but jam to ...</td>\n",
       "      <td>@ByArjix make me one if the columbine school s...</td>\n",
       "      <td>@TyEducatingLibs @Education4Libs The Columbine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mentions</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urls</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photos</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://pbs.twimg.com/media/DW1sSlZWAAAcJEU....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>replies_count</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retweets_count</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likes_count</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hashtags</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['clintongate', 'clintoncash']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cashtags</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link</th>\n",
       "      <td>https://twitter.com/_dmin_/status/809810597734...</td>\n",
       "      <td>https://twitter.com/AIRSPRAY6179/status/596073...</td>\n",
       "      <td>https://twitter.com/poetWOAgun/status/96754857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retweet</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_url</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thumbnail</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/media/DW1sSlZWAAAcJEU.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_rt_id</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_rt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retweet_id</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reply_to</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'Education4Libs', 'name': 'Ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retweet_date</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>translate</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_src</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_dest</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             52383  \\\n",
       "id                                              809810597734924288   \n",
       "conversation_id                                 809810597734924288   \n",
       "created_at                                 2016-12-16 12:21:06 EST   \n",
       "date                                                    2016-12-16   \n",
       "time                                                      12:21:06   \n",
       "timezone                                                      -500   \n",
       "user_id                                         776947029276758016   \n",
       "username                                                    _dmin_   \n",
       "name                                                Destiny Minker   \n",
       "place                                                          NaN   \n",
       "tweet            Y'all wanna freak about a shooting but jam to ...   \n",
       "language                                                        en   \n",
       "mentions                                                        []   \n",
       "urls                                                            []   \n",
       "photos                                                          []   \n",
       "replies_count                                                    0   \n",
       "retweets_count                                                   0   \n",
       "likes_count                                                      2   \n",
       "hashtags                                                        []   \n",
       "cashtags                                                        []   \n",
       "link             https://twitter.com/_dmin_/status/809810597734...   \n",
       "retweet                                                      False   \n",
       "quote_url                                                      NaN   \n",
       "video                                                            0   \n",
       "thumbnail                                                      NaN   \n",
       "near                                                           NaN   \n",
       "geo                                                            NaN   \n",
       "source                                                         NaN   \n",
       "user_rt_id                                                     NaN   \n",
       "user_rt                                                        NaN   \n",
       "retweet_id                                                     NaN   \n",
       "reply_to                                                        []   \n",
       "retweet_date                                                   NaN   \n",
       "translate                                                      NaN   \n",
       "trans_src                                                      NaN   \n",
       "trans_dest                                                     NaN   \n",
       "\n",
       "                                                             58440  \\\n",
       "id                                              596073234635890690   \n",
       "conversation_id                                 592026311796850690   \n",
       "created_at                                 2015-05-06 18:05:08 EDT   \n",
       "date                                                    2015-05-06   \n",
       "time                                                      18:05:08   \n",
       "timezone                                                      -500   \n",
       "user_id                                                 2931195472   \n",
       "username                                              airspray6179   \n",
       "name                                                             s   \n",
       "place                                                          NaN   \n",
       "tweet            @ByArjix make me one if the columbine school s...   \n",
       "language                                                        en   \n",
       "mentions                                                        []   \n",
       "urls                                                            []   \n",
       "photos                                                          []   \n",
       "replies_count                                                    0   \n",
       "retweets_count                                                   0   \n",
       "likes_count                                                      0   \n",
       "hashtags                                                        []   \n",
       "cashtags                                                        []   \n",
       "link             https://twitter.com/AIRSPRAY6179/status/596073...   \n",
       "retweet                                                      False   \n",
       "quote_url                                                      NaN   \n",
       "video                                                            0   \n",
       "thumbnail                                                      NaN   \n",
       "near                                                           NaN   \n",
       "geo                                                            NaN   \n",
       "source                                                         NaN   \n",
       "user_rt_id                                                     NaN   \n",
       "user_rt                                                        NaN   \n",
       "retweet_id                                                     NaN   \n",
       "reply_to                                                        []   \n",
       "retweet_date                                                   NaN   \n",
       "translate                                                      NaN   \n",
       "trans_src                                                      NaN   \n",
       "trans_dest                                                     NaN   \n",
       "\n",
       "                                                             39635  \n",
       "id                                              967548575763673088  \n",
       "conversation_id                                 967521441863225345  \n",
       "created_at                                 2018-02-24 18:55:31 EST  \n",
       "date                                                    2018-02-24  \n",
       "time                                                      18:55:31  \n",
       "timezone                                                      -500  \n",
       "user_id                                         822444348977463296  \n",
       "username                                                poetwoagun  \n",
       "name                                                    poetWOAgun  \n",
       "place                                                          NaN  \n",
       "tweet            @TyEducatingLibs @Education4Libs The Columbine...  \n",
       "language                                                        en  \n",
       "mentions                                                        []  \n",
       "urls                                                            []  \n",
       "photos           ['https://pbs.twimg.com/media/DW1sSlZWAAAcJEU....  \n",
       "replies_count                                                    0  \n",
       "retweets_count                                                   1  \n",
       "likes_count                                                      1  \n",
       "hashtags                            ['clintongate', 'clintoncash']  \n",
       "cashtags                                                        []  \n",
       "link             https://twitter.com/poetWOAgun/status/96754857...  \n",
       "retweet                                                      False  \n",
       "quote_url                                                      NaN  \n",
       "video                                                            1  \n",
       "thumbnail          https://pbs.twimg.com/media/DW1sSlZWAAAcJEU.jpg  \n",
       "near                                                           NaN  \n",
       "geo                                                            NaN  \n",
       "source                                                         NaN  \n",
       "user_rt_id                                                     NaN  \n",
       "user_rt                                                        NaN  \n",
       "retweet_id                                                     NaN  \n",
       "reply_to         [{'screen_name': 'Education4Libs', 'name': 'Ed...  \n",
       "retweet_date                                                   NaN  \n",
       "translate                                                      NaN  \n",
       "trans_src                                                      NaN  \n",
       "trans_dest                                                     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the books.csv file as a DataFrame\n",
    "df = pd.read_csv('columbineC.csv')\n",
    "df.sample(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the \"columbineC.csv\" file.\n",
      "\n",
      "CSV File Shape:\n",
      " (92972, 36)\n",
      "\n",
      "\n",
      "CSV Column Titles:\n",
      " Index(['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone',\n",
      "       'user_id', 'username', 'name', 'place', 'tweet', 'language', 'mentions',\n",
      "       'urls', 'photos', 'replies_count', 'retweets_count', 'likes_count',\n",
      "       'hashtags', 'cashtags', 'link', 'retweet', 'quote_url', 'video',\n",
      "       'thumbnail', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n",
      "       'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src',\n",
      "       'trans_dest'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('From the \"columbineC.csv\" file.\\n')\n",
    "print('CSV File Shape:\\n',df.shape)\n",
    "print('\\n\\nCSV Column Titles:\\n',df.columns)\n",
    "# print('\\n\\nHashtag Value Counts:\\n', df.hashtags.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354412889              371\n",
       "81536715               362\n",
       "613404995              244\n",
       "417862287              125\n",
       "343356408              121\n",
       "                      ... \n",
       "3038361758               1\n",
       "309436573                1\n",
       "1211293734991622145      1\n",
       "1447794842               1\n",
       "569638912                1\n",
       "Name: user_id, Length: 71579, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make hashtag column into list of values, all_tags will list every hashtag\n",
    "\n",
    "all_tags = []\n",
    "for b in df['hashtags']:\n",
    "    c = str(b).split(\", \")\n",
    "    c = str(c).replace('[', '')\n",
    "    c = str(c).replace(']', '')\n",
    "    c = str(c).replace(\"'\", '')\n",
    "    c = str(c).replace('\"', '')\n",
    "    c = str(c).split(', ')\n",
    "    for element in c:\n",
    "        all_tags.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top 10 Most Frequent Hashtags: \n",
      " ['', 'columbine', 'columbineshooting', 'shooting', 'nationalschoolwalkout', 'guncontrol', 'neveragain', 'momsdemandaction', 'parkland', 'guncontrolnow']\n",
      "\n",
      "\n",
      "Count of Top 10 Most Frequent Hashtags: \n",
      " {'': 75936, 'columbine': 3889, 'columbineshooting': 796, 'shooting': 614, 'nationalschoolwalkout': 498, 'guncontrol': 399, 'neveragain': 398, 'momsdemandaction': 396, 'parkland': 376, 'guncontrolnow': 363}\n"
     ]
    }
   ],
   "source": [
    "# Find the top 10 hashtags\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "hashtag_count = dict(Counter(all_tags))\n",
    "\n",
    "print('\\n\\nTop 10 Most Frequent Hashtags: \\n', sorted(hashtag_count, key=hashtag_count.get, reverse=True)[:10])\n",
    "#  or \n",
    "print('\\n\\nCount of Top 10 Most Frequent Hashtags: \\n',dict(Counter(hashtag_count).most_common(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top 10 Most Frequent Usernames: \n",
      " ['hollowtowers', 'letsrollforums', 'pacostacos2525', 'prasannabidkar', 'juaqin11', 'sirenshaper', 'pulpnews', 'norma769', 'votingamerican9', 'bullying_done']\n",
      "\n",
      "\n",
      "Count of Top 10 Most Frequent Usernames: \n",
      " {'hollowtowers': 371, 'letsrollforums': 362, 'pacostacos2525': 244, 'prasannabidkar': 125, 'juaqin11': 121, 'sirenshaper': 104, 'pulpnews': 85, 'norma769': 73, 'votingamerican9': 68, 'bullying_done': 62} \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92972 entries, 0 to 92971\n",
      "Data columns (total 36 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               92972 non-null  int64  \n",
      " 1   conversation_id  92972 non-null  int64  \n",
      " 2   created_at       92972 non-null  object \n",
      " 3   date             92972 non-null  object \n",
      " 4   time             92972 non-null  object \n",
      " 5   timezone         92972 non-null  int64  \n",
      " 6   user_id          92972 non-null  int64  \n",
      " 7   username         92972 non-null  object \n",
      " 8   name             92950 non-null  object \n",
      " 9   place            720 non-null    object \n",
      " 10  tweet            92972 non-null  object \n",
      " 11  language         92972 non-null  object \n",
      " 12  mentions         92972 non-null  object \n",
      " 13  urls             92972 non-null  object \n",
      " 14  photos           92972 non-null  object \n",
      " 15  replies_count    92972 non-null  int64  \n",
      " 16  retweets_count   92972 non-null  int64  \n",
      " 17  likes_count      92972 non-null  int64  \n",
      " 18  hashtags         92972 non-null  object \n",
      " 19  cashtags         92972 non-null  object \n",
      " 20  link             92972 non-null  object \n",
      " 21  retweet          92972 non-null  bool   \n",
      " 22  quote_url        3855 non-null   object \n",
      " 23  video            92972 non-null  int64  \n",
      " 24  thumbnail        7454 non-null   object \n",
      " 25  near             0 non-null      float64\n",
      " 26  geo              0 non-null      float64\n",
      " 27  source           0 non-null      float64\n",
      " 28  user_rt_id       0 non-null      float64\n",
      " 29  user_rt          0 non-null      float64\n",
      " 30  retweet_id       0 non-null      float64\n",
      " 31  reply_to         92972 non-null  object \n",
      " 32  retweet_date     0 non-null      float64\n",
      " 33  translate        0 non-null      float64\n",
      " 34  trans_src        0 non-null      float64\n",
      " 35  trans_dest       0 non-null      float64\n",
      "dtypes: bool(1), float64(10), int64(8), object(17)\n",
      "memory usage: 24.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- username frequency ------------------------\n",
    "\n",
    "usernames = []\n",
    "for b in df['username']:\n",
    "    usernames.append(b)\n",
    "\n",
    "username_count = dict(Counter(usernames))\n",
    "\n",
    "print('\\n\\nTop 10 Most Frequent Usernames: \\n', sorted(username_count, key=username_count.get, reverse=True)[:10])\n",
    "#  or \n",
    "print('\\n\\nCount of Top 10 Most Frequent Usernames: \\n',dict(Counter(username_count).most_common(10)), '\\n\\n',)\n",
    "\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1349518189688832001</td>\n",
       "      <td>1349494392927604737</td>\n",
       "      <td>2021-01-13 16:46:23 PST</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>16:46:23</td>\n",
       "      <td>-800</td>\n",
       "      <td>1033477624624889857</td>\n",
       "      <td>huntergirch3</td>\n",
       "      <td>Hunter Girch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'CoachJBHall', 'name': 'JB Ha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1349486322172350465</td>\n",
       "      <td>1349477039431053313</td>\n",
       "      <td>2021-01-13 14:39:46 PST</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>14:39:46</td>\n",
       "      <td>-800</td>\n",
       "      <td>1033477624624889857</td>\n",
       "      <td>huntergirch3</td>\n",
       "      <td>Hunter Girch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'CoachPrier', 'name': 'COACH ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1342530921338171393</td>\n",
       "      <td>1342530921338171393</td>\n",
       "      <td>2020-12-25 10:01:29 PST</td>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>10:01:29</td>\n",
       "      <td>-800</td>\n",
       "      <td>2474742906</td>\n",
       "      <td>justinnaranjo5</td>\n",
       "      <td>Justin Naranjo</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [34.44167533,...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1330733949103067144</td>\n",
       "      <td>1330733949103067144</td>\n",
       "      <td>2020-11-22 20:44:31 PST</td>\n",
       "      <td>2020-11-22</td>\n",
       "      <td>20:44:31</td>\n",
       "      <td>-800</td>\n",
       "      <td>2474742906</td>\n",
       "      <td>justinnaranjo5</td>\n",
       "      <td>Justin Naranjo</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [34.44167533,...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1330727486842425347</td>\n",
       "      <td>1330727486842425347</td>\n",
       "      <td>2020-11-22 20:18:51 PST</td>\n",
       "      <td>2020-11-22</td>\n",
       "      <td>20:18:51</td>\n",
       "      <td>-800</td>\n",
       "      <td>2474742906</td>\n",
       "      <td>justinnaranjo5</td>\n",
       "      <td>Justin Naranjo</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [34.44167533,...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>1196330757351854080</td>\n",
       "      <td>1196330757351854080</td>\n",
       "      <td>2019-11-17 23:34:13 PST</td>\n",
       "      <td>2019-11-17</td>\n",
       "      <td>23:34:13</td>\n",
       "      <td>-800</td>\n",
       "      <td>72602891</td>\n",
       "      <td>acalagias</td>\n",
       "      <td>alethia calagias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>1196329060248379392</td>\n",
       "      <td>1196329060248379392</td>\n",
       "      <td>2019-11-17 23:27:29 PST</td>\n",
       "      <td>2019-11-17</td>\n",
       "      <td>23:27:29</td>\n",
       "      <td>-800</td>\n",
       "      <td>2842305256</td>\n",
       "      <td>tiedtohope</td>\n",
       "      <td>Rev. Dr. V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>1196317264540127233</td>\n",
       "      <td>1196317264540127233</td>\n",
       "      <td>2019-11-17 22:40:37 PST</td>\n",
       "      <td>2019-11-17</td>\n",
       "      <td>22:40:37</td>\n",
       "      <td>-800</td>\n",
       "      <td>968788490</td>\n",
       "      <td>austindave_</td>\n",
       "      <td>Austin Dave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>1196310410586017794</td>\n",
       "      <td>1196310410586017794</td>\n",
       "      <td>2019-11-17 22:13:22 PST</td>\n",
       "      <td>2019-11-17</td>\n",
       "      <td>22:13:22</td>\n",
       "      <td>-800</td>\n",
       "      <td>758899526602149888</td>\n",
       "      <td>emilyfiitz</td>\n",
       "      <td>emily fitzgerald ✨</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1196298029755588608</td>\n",
       "      <td>1196298029755588608</td>\n",
       "      <td>2019-11-17 21:24:11 PST</td>\n",
       "      <td>2019-11-17</td>\n",
       "      <td>21:24:11</td>\n",
       "      <td>-800</td>\n",
       "      <td>148961900</td>\n",
       "      <td>passthepinot</td>\n",
       "      <td>LoriG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>541 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id      conversation_id               created_at  \\\n",
       "0    1349518189688832001  1349494392927604737  2021-01-13 16:46:23 PST   \n",
       "1    1349486322172350465  1349477039431053313  2021-01-13 14:39:46 PST   \n",
       "2    1342530921338171393  1342530921338171393  2020-12-25 10:01:29 PST   \n",
       "3    1330733949103067144  1330733949103067144  2020-11-22 20:44:31 PST   \n",
       "4    1330727486842425347  1330727486842425347  2020-11-22 20:18:51 PST   \n",
       "..                   ...                  ...                      ...   \n",
       "536  1196330757351854080  1196330757351854080  2019-11-17 23:34:13 PST   \n",
       "537  1196329060248379392  1196329060248379392  2019-11-17 23:27:29 PST   \n",
       "538  1196317264540127233  1196317264540127233  2019-11-17 22:40:37 PST   \n",
       "539  1196310410586017794  1196310410586017794  2019-11-17 22:13:22 PST   \n",
       "540  1196298029755588608  1196298029755588608  2019-11-17 21:24:11 PST   \n",
       "\n",
       "           date      time  timezone              user_id        username  \\\n",
       "0    2021-01-13  16:46:23      -800  1033477624624889857    huntergirch3   \n",
       "1    2021-01-13  14:39:46      -800  1033477624624889857    huntergirch3   \n",
       "2    2020-12-25  10:01:29      -800           2474742906  justinnaranjo5   \n",
       "3    2020-11-22  20:44:31      -800           2474742906  justinnaranjo5   \n",
       "4    2020-11-22  20:18:51      -800           2474742906  justinnaranjo5   \n",
       "..          ...       ...       ...                  ...             ...   \n",
       "536  2019-11-17  23:34:13      -800             72602891       acalagias   \n",
       "537  2019-11-17  23:27:29      -800           2842305256      tiedtohope   \n",
       "538  2019-11-17  22:40:37      -800            968788490     austindave_   \n",
       "539  2019-11-17  22:13:22      -800   758899526602149888      emilyfiitz   \n",
       "540  2019-11-17  21:24:11      -800            148961900    passthepinot   \n",
       "\n",
       "                   name                                              place  \\\n",
       "0          Hunter Girch                                                NaN   \n",
       "1          Hunter Girch                                                NaN   \n",
       "2        Justin Naranjo  {'type': 'Point', 'coordinates': [34.44167533,...   \n",
       "3        Justin Naranjo  {'type': 'Point', 'coordinates': [34.44167533,...   \n",
       "4        Justin Naranjo  {'type': 'Point', 'coordinates': [34.44167533,...   \n",
       "..                  ...                                                ...   \n",
       "536    alethia calagias                                                NaN   \n",
       "537          Rev. Dr. V                                                NaN   \n",
       "538         Austin Dave                                                NaN   \n",
       "539  emily fitzgerald ✨                                                NaN   \n",
       "540               LoriG                                                NaN   \n",
       "\n",
       "     ... geo source user_rt_id user_rt retweet_id  \\\n",
       "0    ... NaN    NaN        NaN     NaN        NaN   \n",
       "1    ... NaN    NaN        NaN     NaN        NaN   \n",
       "2    ... NaN    NaN        NaN     NaN        NaN   \n",
       "3    ... NaN    NaN        NaN     NaN        NaN   \n",
       "4    ... NaN    NaN        NaN     NaN        NaN   \n",
       "..   ...  ..    ...        ...     ...        ...   \n",
       "536  ... NaN    NaN        NaN     NaN        NaN   \n",
       "537  ... NaN    NaN        NaN     NaN        NaN   \n",
       "538  ... NaN    NaN        NaN     NaN        NaN   \n",
       "539  ... NaN    NaN        NaN     NaN        NaN   \n",
       "540  ... NaN    NaN        NaN     NaN        NaN   \n",
       "\n",
       "                                              reply_to  retweet_date  \\\n",
       "0    [{'screen_name': 'CoachJBHall', 'name': 'JB Ha...           NaN   \n",
       "1    [{'screen_name': 'CoachPrier', 'name': 'COACH ...           NaN   \n",
       "2                                                   []           NaN   \n",
       "3                                                   []           NaN   \n",
       "4                                                   []           NaN   \n",
       "..                                                 ...           ...   \n",
       "536                                                 []           NaN   \n",
       "537                                                 []           NaN   \n",
       "538                                                 []           NaN   \n",
       "539                                                 []           NaN   \n",
       "540                                                 []           NaN   \n",
       "\n",
       "     translate trans_src trans_dest  \n",
       "0          NaN       NaN        NaN  \n",
       "1          NaN       NaN        NaN  \n",
       "2          NaN       NaN        NaN  \n",
       "3          NaN       NaN        NaN  \n",
       "4          NaN       NaN        NaN  \n",
       "..         ...       ...        ...  \n",
       "536        NaN       NaN        NaN  \n",
       "537        NaN       NaN        NaN  \n",
       "538        NaN       NaN        NaN  \n",
       "539        NaN       NaN        NaN  \n",
       "540        NaN       NaN        NaN  \n",
       "\n",
       "[541 rows x 36 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "'''preparing a csv to use for further analysis'''\n",
    "\n",
    "# ---Import libraries---\n",
    "%run lib/__wesley_init__.py\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from datetime import *\n",
    "from tqdm import tqdm\n",
    "from decimal import Decimal\n",
    "\n",
    "print('Libraries loaded') #Progress check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtags_used_count(username):\n",
    "    from collections import Counter\n",
    "    username_sorted_df = df[df['username'] == username]\n",
    "    all_tags = []\n",
    "    for b in username_sorted_df['hashtags']:\n",
    "        c = str(b).split(\", \")\n",
    "        c = str(c).replace('[', '')\n",
    "        c = str(c).replace(']', '')\n",
    "        c = str(c).replace(\"'\", '')\n",
    "        c = str(c).replace('\"', '')\n",
    "        c = str(c).split(', ')\n",
    "        for element in c:\n",
    "            all_tags.append(element)\n",
    "    \n",
    "    hashtag_count = dict(Counter(all_tags))\n",
    "    return hashtag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashtag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'delta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-8d256c2bc9fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdelta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'delta' is not defined"
     ]
    }
   ],
   "source": [
    "def min_max_date(username):\n",
    "    from collections import Counter\n",
    "    username_sorted_df = df[df['username'] == username]\n",
    "    username_sorted_df = username_sorted_df.reset_index(drop=True)\n",
    "    min_date = min(username_sorted_df['date'])\n",
    "    max_date = max(username_sorted_df['date'])\n",
    "    return min_date, max_date\n",
    "\n",
    "def count_days(min_date, max_date):\n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    min_date = datetime.strptime(min_date, date_format)\n",
    "    max_date = datetime.strptime(max_date, date_format)\n",
    "    delta = max_date - min_date\n",
    "    return delta.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2021-01-13', '2021-01-13')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_date('huntergirch3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_days(min_date, max_date):\n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    min_date = datetime.strptime(min_date, date_format)\n",
    "    max_date = datetime.strptime(max_date, date_format)\n",
    "    delta = max_date - min_date\n",
    "    return delta.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_days('2021-01-13', '2021-01-13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mentions(df):\n",
    "    mentions = []\n",
    "    for tweet in df['tweet']:\n",
    "        tokened_tweet = tokenize_by_words2(tweet)\n",
    "        for word in tokened_tweet:\n",
    "            if '@' in word:\n",
    "                mentions.append(word)\n",
    "    mention_count = Counter(mentions)\n",
    "    return mention_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'@CoachJBHall': 1,\n",
       "         '@zoom_us': 1,\n",
       "         '@CoachPrier': 2,\n",
       "         '@ISUBengals': 1,\n",
       "         '@IdahoStateFB': 1,\n",
       "         '@pavel_who': 1,\n",
       "         '@': 271,\n",
       "         '@graciestrongnow': 2,\n",
       "         '@colettemiller': 1,\n",
       "         '@GracieStrongNow,': 1,\n",
       "         '@FredNBCLA': 1,\n",
       "         '@Pliableone': 1,\n",
       "         '@Apryl404': 1,\n",
       "         '@Cents_Baseball': 1,\n",
       "         '@SignalSports': 1,\n",
       "         '@latsondheimer': 1,\n",
       "         '@LesLukach': 1,\n",
       "         '@NDSO_Athletics': 1,\n",
       "         '@LacrosseSaugus': 1,\n",
       "         '@…': 1,\n",
       "         '@hart_basketball': 1,\n",
       "         '@SaugusHoops': 1,\n",
       "         '@TTaesarang': 1,\n",
       "         '@m_mendozaferrer': 1,\n",
       "         '@cgrapski': 1,\n",
       "         '@TinaDesireeBerg': 1,\n",
       "         '@gingercaddy': 1,\n",
       "         '@BernieSanders': 1,\n",
       "         '@cenkuygur': 1,\n",
       "         'CBS2@11': 1,\n",
       "         '@CBSLA': 1,\n",
       "         '@SpecNews1SoCal': 1,\n",
       "         '@ABSCBNNews': 1,\n",
       "         '@ANCALERTS': 1,\n",
       "         '@balitangamerica': 1,\n",
       "         '@ABC7': 3,\n",
       "         '@sierracanyon': 1,\n",
       "         '@saugusasb': 1,\n",
       "         '@todayshow': 1,\n",
       "         '@everytown': 1,\n",
       "         '@tifamela': 1,\n",
       "         '@laist': 1,\n",
       "         '@FOXLA': 2,\n",
       "         '@GDLA': 1,\n",
       "         '@AP': 1,\n",
       "         '@AP_Images': 1,\n",
       "         '@NRA': 1,\n",
       "         '@PierceMediaArts': 1,\n",
       "         '@JillphotoLA': 1,\n",
       "         '(@SaugusHigh)': 1,\n",
       "         '@SaugusGridiron': 1,\n",
       "         '@BaskinNewhall': 4,\n",
       "         '@Saugus_VB': 1,\n",
       "         '(@': 63,\n",
       "         '@maggieedoty': 1,\n",
       "         '@awinghart': 1,\n",
       "         '@saugusnewtoday': 1,\n",
       "         '@bryan_steinerr3': 1,\n",
       "         '@usacamps': 2,\n",
       "         '“@Real_Liam_Payne:': 1,\n",
       "         '@boybandproject': 1,\n",
       "         '@BauerOutage': 1,\n",
       "         '@TommyMilone_57': 1,\n",
       "         '@ChloeRene19': 1,\n",
       "         '@movementincdc': 1,\n",
       "         '@TheSoCalHiker': 1,\n",
       "         '“@SCVconfessions:': 1,\n",
       "         '@KNOKXPRO': 1,\n",
       "         '@CameronDallas': 1,\n",
       "         '@SwarmingBRadio': 1,\n",
       "         '@jay_tobes': 1,\n",
       "         '@seekmynebula': 1,\n",
       "         '“@CameronDallas:': 1,\n",
       "         '@CourtneyConradd': 1,\n",
       "         '@zachgarl': 1,\n",
       "         '“@thebigfarshman:': 1,\n",
       "         '@zFarbs7': 1,\n",
       "         '@shannonwestlake': 1,\n",
       "         '@zachgarlitos': 1,\n",
       "         '@austenscheff33': 2,\n",
       "         '@tito_o1': 1,\n",
       "         '@celesteiniguez': 2,\n",
       "         '@dennrodd': 1,\n",
       "         '@xoxocheydav': 1,\n",
       "         '@mstezzy13': 1,\n",
       "         '@SaugusHigh': 1,\n",
       "         '@SaugusAthletics': 1,\n",
       "         '@Saugus_cents': 1,\n",
       "         '@SAUGUS_BLUECREW': 1,\n",
       "         '@santaclarita': 1})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_mentions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_created_at_column(df, csv_name):\n",
    "    iterator = 0\n",
    "    counter = 0\n",
    "    fmt = '%Y-%m-%d %H:%M:%S'\n",
    "    for _ in tqdm(df.created_at): \n",
    "        df.loc[iterator, 'created_at'] = df.loc[iterator, 'created_at'].replace(' PST', '')\n",
    "        df.loc[iterator, 'created_at'] = df.loc[iterator, 'created_at'].replace(' PDT', '')\n",
    "        iterator += 1\n",
    "        counter += 1\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 541/541 [00:00<00:00, 9326.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-13 16:46:23\n",
      "2021-01-13 14:39:46\n",
      "2020-12-25 10:01:29\n",
      "2020-11-22 20:44:31\n",
      "2020-11-22 20:18:51\n",
      "2020-11-22 20:08:20\n",
      "2020-11-16 12:14:09\n",
      "2020-11-03 02:43:11\n",
      "2020-10-31 16:04:07\n",
      "2020-10-18 14:27:43\n",
      "2020-10-10 18:02:52\n",
      "2020-09-19 23:24:34\n",
      "2020-09-19 23:17:55\n",
      "2020-06-05 17:52:01\n",
      "2020-06-03 23:07:31\n",
      "2020-05-24 10:16:54\n",
      "2020-04-18 14:01:13\n",
      "2020-04-18 11:13:34\n",
      "2020-04-07 17:01:42\n",
      "2020-04-07 16:59:04\n",
      "2020-03-23 15:30:14\n",
      "2020-03-23 15:23:36\n",
      "2020-03-22 21:45:23\n",
      "2020-03-22 21:38:41\n",
      "2020-03-22 21:30:12\n",
      "2020-03-22 11:29:39\n",
      "2020-03-22 10:34:54\n",
      "2020-03-18 21:11:35\n",
      "2020-03-18 20:57:09\n",
      "2020-03-18 11:31:34\n",
      "2020-03-16 10:02:36\n",
      "2020-03-16 09:57:18\n",
      "2020-03-16 09:55:09\n",
      "2020-03-16 09:44:07\n",
      "2020-03-16 09:41:39\n",
      "2020-03-15 09:47:34\n",
      "2020-03-15 09:37:50\n",
      "2020-03-11 15:46:01\n",
      "2020-03-10 21:34:10\n",
      "2020-03-10 21:31:29\n",
      "2020-03-09 17:14:12\n",
      "2020-03-09 17:09:11\n",
      "2020-03-09 17:07:02\n",
      "2020-03-06 10:00:49\n",
      "2020-03-05 11:42:27\n",
      "2020-03-05 08:26:36\n",
      "2020-03-03 19:24:47\n",
      "2020-03-03 16:32:41\n",
      "2020-03-03 16:22:31\n",
      "2020-03-02 20:03:41\n",
      "2020-03-02 20:00:03\n",
      "2020-03-02 19:55:48\n",
      "2020-02-29 15:17:27\n",
      "2020-02-28 21:41:12\n",
      "2020-02-28 21:32:40\n",
      "2020-02-28 21:07:38\n",
      "2020-02-28 17:03:22\n",
      "2020-02-28 16:59:33\n",
      "2020-02-27 08:34:06\n",
      "2020-02-24 19:44:24\n",
      "2020-02-24 19:40:31\n",
      "2020-02-24 19:33:29\n",
      "2020-02-23 18:35:24\n",
      "2020-02-23 18:32:43\n",
      "2020-02-23 18:30:15\n",
      "2020-02-23 18:16:36\n",
      "2020-02-22 17:02:30\n",
      "2020-02-22 16:32:59\n",
      "2020-02-22 11:43:55\n",
      "2020-02-22 11:42:29\n",
      "2020-02-22 09:21:24\n",
      "2020-02-22 09:05:37\n",
      "2020-02-22 09:00:50\n",
      "2020-02-22 08:55:10\n",
      "2020-02-20 17:56:09\n",
      "2020-02-20 17:00:24\n",
      "2020-02-20 16:56:28\n",
      "2020-02-20 16:52:26\n",
      "2020-02-19 21:59:13\n",
      "2020-02-19 21:54:48\n",
      "2020-02-19 21:50:19\n",
      "2020-02-18 19:21:42\n",
      "2020-02-17 20:56:12\n",
      "2020-02-17 17:34:12\n",
      "2020-02-17 17:28:11\n",
      "2020-02-16 13:04:06\n",
      "2020-02-13 10:54:52\n",
      "2020-02-09 19:20:17\n",
      "2020-02-09 12:44:02\n",
      "2020-02-09 12:13:52\n",
      "2020-02-09 09:55:24\n",
      "2020-02-09 09:33:06\n",
      "2020-02-08 12:04:25\n",
      "2020-02-01 06:32:32\n",
      "2020-01-23 09:10:58\n",
      "2020-01-21 18:22:10\n",
      "2019-12-20 15:24:26\n",
      "2019-12-18 16:26:43\n",
      "2019-12-15 04:36:32\n",
      "2019-12-03 01:14:17\n",
      "2019-12-02 20:48:33\n",
      "2019-12-02 06:41:43\n",
      "2019-11-24 14:17:26\n",
      "2019-11-22 22:20:23\n",
      "2019-11-22 15:32:40\n",
      "2019-11-20 10:27:19\n",
      "2019-11-19 22:38:23\n",
      "2019-11-19 14:23:05\n",
      "2019-11-19 13:32:47\n",
      "2019-11-19 12:00:22\n",
      "2019-11-18 11:14:54\n",
      "2019-11-18 07:15:57\n",
      "2019-11-18 00:10:56\n",
      "2019-11-17 21:21:20\n",
      "2019-11-17 20:11:12\n",
      "2019-11-17 20:01:34\n",
      "2019-11-17 19:12:02\n",
      "2019-11-16 21:53:08\n",
      "2019-11-16 11:28:45\n",
      "2019-11-16 09:00:32\n",
      "2019-11-15 22:58:37\n",
      "2019-11-15 20:40:52\n",
      "2019-11-15 19:55:18\n",
      "2019-11-15 17:26:39\n",
      "2019-11-15 17:18:26\n",
      "2019-11-15 15:08:44\n",
      "2019-11-15 14:54:14\n",
      "2019-11-15 09:55:02\n",
      "2019-11-15 09:20:44\n",
      "2019-11-15 08:57:04\n",
      "2019-11-15 08:41:33\n",
      "2019-11-15 03:57:12\n",
      "2019-11-15 00:46:38\n",
      "2019-11-14 22:57:54\n",
      "2019-11-14 22:47:51\n",
      "2019-11-14 22:47:46\n",
      "2019-11-14 22:08:43\n",
      "2019-11-14 19:14:27\n",
      "2019-11-14 18:21:11\n",
      "2019-11-14 18:06:09\n",
      "2019-11-14 17:21:58\n",
      "2019-11-14 17:21:09\n",
      "2019-11-14 17:02:58\n",
      "2019-11-14 16:59:20\n",
      "2019-11-14 15:20:28\n",
      "2019-11-14 14:32:09\n",
      "2019-11-14 14:18:15\n",
      "2019-11-14 14:11:37\n",
      "2019-11-14 13:35:37\n",
      "2019-11-14 13:12:37\n",
      "2019-11-14 12:04:17\n",
      "2019-11-14 12:04:05\n",
      "2019-11-14 11:56:42\n",
      "2019-11-14 11:34:04\n",
      "2019-11-14 11:20:02\n",
      "2019-11-14 11:14:17\n",
      "2019-11-14 11:13:14\n",
      "2019-11-14 10:53:23\n",
      "2019-11-14 10:46:45\n",
      "2019-11-14 10:30:07\n",
      "2019-11-14 10:23:36\n",
      "2019-11-14 10:13:06\n",
      "2019-11-14 10:04:03\n",
      "2019-11-14 09:38:35\n",
      "2019-11-14 09:27:10\n",
      "2019-11-14 09:25:25\n",
      "2019-11-14 09:09:34\n",
      "2019-11-14 09:08:43\n",
      "2019-11-14 09:06:45\n",
      "2019-11-14 08:46:24\n",
      "2019-11-14 08:44:57\n",
      "2019-11-14 08:39:30\n",
      "2019-11-14 08:37:51\n",
      "2019-11-14 08:36:53\n",
      "2019-11-14 08:31:51\n",
      "2019-11-14 08:31:02\n",
      "2019-11-14 08:30:31\n",
      "2019-11-14 08:24:01\n",
      "2019-11-14 08:14:09\n",
      "2019-11-14 08:11:27\n",
      "2019-11-14 07:53:14\n",
      "2019-11-14 07:52:54\n",
      "2019-11-02 12:01:12\n",
      "2019-10-11 12:46:33\n",
      "2019-08-28 16:10:19\n",
      "2019-08-09 19:28:04\n",
      "2019-06-28 16:45:29\n",
      "2019-06-21 17:57:52\n",
      "2019-06-21 13:32:46\n",
      "2019-06-21 13:28:25\n",
      "2019-06-10 11:04:08\n",
      "2019-06-06 08:41:21\n",
      "2019-06-05 07:21:54\n",
      "2019-05-14 21:34:23\n",
      "2019-04-29 20:09:58\n",
      "2019-04-29 19:04:46\n",
      "2019-04-29 19:03:22\n",
      "2019-04-29 18:14:55\n",
      "2019-04-29 17:57:12\n",
      "2019-04-27 16:53:12\n",
      "2019-04-27 16:52:09\n",
      "2019-04-25 18:35:45\n",
      "2019-04-25 18:17:24\n",
      "2019-04-22 19:06:52\n",
      "2019-04-22 17:45:51\n",
      "2019-04-18 19:04:14\n",
      "2019-04-17 11:31:57\n",
      "2019-04-17 11:31:03\n",
      "2019-04-11 19:47:29\n",
      "2019-04-10 09:09:26\n",
      "2019-04-10 09:08:22\n",
      "2019-04-09 21:25:07\n",
      "2019-04-09 18:54:25\n",
      "2019-04-08 13:14:13\n",
      "2019-04-08 13:12:33\n",
      "2019-04-06 20:58:19\n",
      "2019-04-06 11:48:09\n",
      "2019-03-30 15:33:14\n",
      "2019-03-30 13:50:58\n",
      "2019-03-28 20:46:59\n",
      "2019-03-28 20:22:39\n",
      "2019-03-28 20:20:29\n",
      "2019-03-27 20:03:43\n",
      "2019-03-27 19:13:25\n",
      "2019-03-27 18:02:37\n",
      "2019-03-27 17:19:00\n",
      "2019-03-27 15:11:58\n",
      "2019-03-27 14:50:27\n",
      "2019-03-21 17:50:20\n",
      "2019-03-20 16:20:57\n",
      "2019-02-28 15:54:32\n",
      "2019-02-24 11:09:02\n",
      "2019-02-18 19:44:24\n",
      "2019-02-18 19:43:04\n",
      "2019-02-17 11:33:57\n",
      "2019-02-17 11:32:53\n",
      "2019-02-02 14:26:24\n",
      "2019-01-01 09:48:21\n",
      "2018-12-08 12:05:35\n",
      "2018-10-29 20:53:33\n",
      "2018-10-12 20:07:23\n",
      "2018-10-09 21:49:32\n",
      "2018-10-07 09:08:28\n",
      "2018-10-06 12:31:00\n",
      "2018-10-05 20:11:32\n",
      "2018-10-01 14:01:31\n",
      "2018-09-27 16:16:13\n",
      "2018-09-13 21:29:48\n",
      "2018-09-08 08:30:59\n",
      "2018-09-05 21:17:42\n",
      "2018-08-08 12:26:41\n",
      "2018-07-02 14:04:02\n",
      "2018-06-28 17:17:45\n",
      "2018-06-08 13:37:08\n",
      "2018-05-05 17:03:43\n",
      "2018-04-21 00:42:38\n",
      "2018-04-17 21:31:59\n",
      "2018-03-24 09:37:34\n",
      "2018-03-10 18:06:09\n",
      "2018-03-10 18:05:59\n",
      "2018-02-10 08:36:40\n",
      "2017-11-11 18:40:20\n",
      "2017-11-11 18:40:06\n",
      "2017-11-11 18:39:55\n",
      "2017-11-11 18:39:41\n",
      "2017-11-09 10:30:17\n",
      "2017-10-23 16:00:58\n",
      "2017-10-01 18:58:12\n",
      "2017-09-02 07:09:38\n",
      "2017-08-26 13:10:52\n",
      "2017-08-26 12:58:03\n",
      "2017-07-05 11:53:57\n",
      "2017-05-15 20:54:43\n",
      "2017-05-06 10:56:17\n",
      "2017-04-02 11:55:50\n",
      "2017-03-17 15:47:31\n",
      "2017-03-09 14:12:53\n",
      "2017-02-13 20:55:51\n",
      "2017-02-11 07:58:20\n",
      "2017-02-03 15:09:27\n",
      "2017-01-28 20:35:52\n",
      "2017-01-16 12:19:44\n",
      "2017-01-14 14:43:08\n",
      "2017-01-13 09:15:21\n",
      "2016-10-24 20:59:05\n",
      "2016-10-10 08:38:11\n",
      "2016-10-01 20:18:42\n",
      "2016-09-26 19:55:11\n",
      "2016-09-21 22:18:14\n",
      "2016-08-29 21:03:32\n",
      "2016-08-26 12:27:28\n",
      "2016-08-24 16:42:18\n",
      "2016-08-22 08:18:43\n",
      "2016-08-20 10:31:21\n",
      "2016-08-19 14:49:48\n",
      "2016-08-18 07:50:11\n",
      "2016-08-16 18:28:08\n",
      "2016-08-15 19:52:16\n",
      "2016-08-15 13:09:34\n",
      "2016-08-15 10:43:45\n",
      "2016-08-10 07:54:57\n",
      "2016-07-29 09:25:18\n",
      "2016-06-30 21:34:11\n",
      "2016-04-30 18:31:46\n",
      "2016-04-23 10:05:26\n",
      "2016-04-22 18:45:46\n",
      "2016-04-20 09:00:51\n",
      "2016-04-20 09:00:00\n",
      "2016-04-15 17:39:44\n",
      "2015-11-25 16:10:10\n",
      "2015-10-22 19:20:11\n",
      "2015-08-27 19:44:19\n",
      "2015-08-14 23:20:38\n",
      "2015-05-12 21:35:45\n",
      "2015-03-31 07:27:05\n",
      "2015-03-29 14:42:28\n",
      "2015-03-26 21:42:56\n",
      "2015-03-12 16:55:50\n",
      "2015-03-01 18:11:37\n",
      "2015-02-28 17:18:28\n",
      "2015-02-28 15:55:12\n",
      "2015-02-28 11:54:18\n",
      "2015-02-21 13:15:00\n",
      "2015-02-20 21:47:38\n",
      "2015-02-19 10:15:58\n",
      "2015-01-16 17:31:12\n",
      "2015-01-14 09:59:13\n",
      "2015-01-13 17:03:13\n",
      "2014-12-29 14:58:10\n",
      "2014-12-21 17:01:49\n",
      "2014-12-09 00:02:06\n",
      "2014-11-02 17:29:07\n",
      "2014-11-01 11:11:50\n",
      "2014-10-22 23:20:16\n",
      "2014-10-12 17:59:15\n",
      "2014-10-02 19:16:08\n",
      "2014-09-29 18:25:03\n",
      "2014-09-29 17:14:32\n",
      "2014-09-17 17:43:51\n",
      "2014-09-09 17:33:16\n",
      "2014-08-26 16:57:08\n",
      "2014-08-16 13:54:01\n",
      "2014-08-13 20:00:44\n",
      "2014-07-23 17:23:39\n",
      "2014-07-22 21:28:30\n",
      "2014-07-17 08:52:54\n",
      "2014-07-12 19:36:08\n",
      "2014-06-02 20:53:54\n",
      "2014-06-02 18:39:25\n",
      "2014-05-31 12:53:34\n",
      "2014-05-30 09:34:05\n",
      "2014-05-29 21:08:28\n",
      "2014-05-23 21:13:49\n",
      "2014-05-17 09:13:07\n",
      "2014-05-15 20:04:08\n",
      "2014-05-05 07:42:34\n",
      "2014-05-03 18:55:23\n",
      "2014-05-03 11:48:35\n",
      "2014-05-02 13:52:52\n",
      "2014-05-01 08:00:10\n",
      "2014-04-29 20:55:06\n",
      "2014-04-29 18:39:37\n",
      "2014-04-26 17:17:32\n",
      "2014-04-26 12:00:39\n",
      "2014-04-25 13:50:58\n",
      "2014-04-17 18:07:03\n",
      "2014-04-14 21:31:56\n",
      "2014-04-12 00:04:13\n",
      "2014-03-27 21:20:51\n",
      "2014-03-27 16:20:26\n",
      "2014-03-27 11:02:25\n",
      "2014-03-24 20:51:54\n",
      "2014-03-21 07:37:30\n",
      "2014-03-20 16:53:53\n",
      "2014-03-05 21:40:16\n",
      "2014-02-27 20:47:07\n",
      "2014-02-24 20:27:38\n",
      "2014-02-17 20:25:33\n",
      "2014-02-15 21:19:58\n",
      "2014-02-13 14:15:12\n",
      "2014-02-10 20:57:17\n",
      "2014-01-28 18:34:06\n",
      "2014-01-28 14:45:31\n",
      "2014-01-27 21:04:00\n",
      "2014-01-24 16:24:25\n",
      "2014-01-23 20:55:45\n",
      "2014-01-20 20:51:22\n",
      "2014-01-17 14:59:03\n",
      "2014-01-14 17:57:37\n",
      "2014-01-13 20:51:01\n",
      "2014-01-11 18:31:57\n",
      "2014-01-10 16:51:32\n",
      "2014-01-10 14:09:55\n",
      "2014-01-08 17:51:18\n",
      "2013-12-15 19:56:51\n",
      "2013-12-13 21:55:06\n",
      "2013-12-13 18:25:44\n",
      "2013-12-10 20:52:12\n",
      "2013-12-09 20:54:31\n",
      "2013-12-03 20:52:20\n",
      "2013-12-02 21:03:22\n",
      "2013-11-25 20:51:58\n",
      "2013-11-19 20:51:19\n",
      "2013-11-18 21:21:17\n",
      "2013-11-15 13:51:16\n",
      "2013-11-12 21:06:07\n",
      "2013-11-09 19:11:06\n",
      "2013-11-09 14:12:35\n",
      "2013-11-01 15:02:10\n",
      "2013-10-29 20:48:58\n",
      "2013-10-28 20:54:06\n",
      "2013-10-28 20:53:09\n",
      "2013-10-21 20:50:49\n",
      "2013-10-15 20:51:21\n",
      "2013-10-14 20:45:33\n",
      "2013-10-11 13:49:08\n",
      "2013-10-08 20:40:02\n",
      "2013-10-04 14:10:06\n",
      "2013-10-01 20:55:56\n",
      "2013-09-30 20:52:27\n",
      "2013-09-26 19:36:10\n",
      "2013-09-24 20:57:32\n",
      "2013-09-23 20:53:03\n",
      "2013-09-22 21:59:25\n",
      "2013-09-17 18:28:23\n",
      "2013-09-14 07:55:11\n",
      "2013-09-10 20:51:33\n",
      "2013-09-06 15:40:10\n",
      "2013-09-03 20:54:12\n",
      "2013-08-30 13:38:49\n",
      "2013-08-29 16:03:15\n",
      "2013-08-27 21:09:52\n",
      "2013-08-16 14:22:28\n",
      "2013-07-10 21:24:02\n",
      "2013-07-09 21:23:54\n",
      "2013-06-13 19:42:40\n",
      "2013-05-25 16:03:57\n",
      "2013-05-24 20:09:40\n",
      "2013-05-21 08:40:02\n",
      "2013-05-15 20:30:27\n",
      "2013-05-14 13:39:26\n",
      "2013-04-30 15:57:08\n",
      "2013-04-29 21:11:07\n",
      "2013-04-24 08:52:45\n",
      "2013-04-24 08:49:28\n",
      "2013-04-22 18:53:37\n",
      "2013-03-29 11:37:58\n",
      "2013-03-28 16:39:25\n",
      "2013-03-26 13:36:47\n",
      "2013-03-19 13:49:33\n",
      "2013-03-11 20:57:34\n",
      "2013-03-04 09:48:20\n",
      "2013-02-27 07:42:01\n",
      "2013-02-25 20:48:17\n",
      "2013-02-25 12:43:29\n",
      "2013-02-23 11:34:17\n",
      "2013-02-20 18:50:10\n",
      "2013-02-16 11:16:26\n",
      "2013-02-14 08:14:28\n",
      "2013-02-08 14:32:35\n",
      "2013-02-04 18:55:26\n",
      "2013-02-01 07:38:48\n",
      "2013-01-31 08:07:45\n",
      "2013-01-28 20:56:42\n",
      "2013-01-25 13:54:59\n",
      "2013-01-21 20:56:31\n",
      "2013-01-18 13:56:26\n",
      "2013-01-14 21:02:49\n",
      "2013-01-10 16:21:25\n",
      "2013-01-09 15:49:59\n",
      "2013-01-09 14:54:13\n",
      "2013-01-08 15:30:14\n",
      "2013-01-07 16:51:08\n",
      "2013-01-04 15:54:11\n",
      "2013-01-02 16:51:50\n",
      "2012-12-03 21:21:55\n",
      "2012-11-28 09:45:53\n",
      "2012-11-26 13:59:11\n",
      "2012-11-15 10:47:08\n",
      "2012-11-15 09:33:44\n",
      "2012-11-13 17:04:25\n",
      "2012-11-08 11:28:15\n",
      "2012-11-03 14:45:49\n",
      "2012-11-01 15:28:21\n",
      "2012-10-31 14:53:24\n",
      "2012-10-31 11:40:19\n",
      "2012-10-23 09:59:47\n",
      "2012-10-22 20:50:20\n",
      "2012-10-18 11:02:22\n",
      "2012-10-15 20:50:54\n",
      "2012-10-09 23:34:05\n",
      "2012-10-09 11:36:26\n",
      "2012-10-04 23:25:47\n",
      "2012-10-01 20:49:51\n",
      "2012-09-24 21:06:42\n",
      "2012-09-15 21:41:24\n",
      "2012-09-13 16:57:46\n",
      "2012-09-12 11:33:36\n",
      "2012-09-11 09:24:40\n",
      "2012-09-07 09:34:33\n",
      "2012-09-06 09:20:06\n",
      "2012-08-31 09:27:39\n",
      "2012-08-30 11:54:25\n",
      "2012-08-29 00:48:49\n",
      "2012-08-27 12:03:38\n",
      "2012-08-27 08:29:05\n",
      "2012-08-23 19:57:51\n",
      "2012-08-23 18:45:03\n",
      "2012-08-22 22:07:15\n",
      "2012-08-22 17:03:40\n",
      "2012-08-20 20:58:07\n",
      "2012-08-18 15:09:07\n",
      "2012-08-18 12:31:28\n",
      "2012-08-17 22:27:00\n",
      "2012-08-16 17:10:13\n",
      "2012-08-16 11:46:52\n",
      "2012-08-16 06:55:15\n",
      "2012-08-08 18:22:28\n",
      "2012-07-19 09:35:59\n",
      "2012-07-16 18:49:42\n",
      "2012-07-12 18:45:32\n",
      "2012-07-11 21:24:28\n",
      "2012-07-09 21:31:52\n",
      "2012-06-19 16:06:04\n",
      "2012-06-01 10:21:37\n",
      "2012-05-29 10:19:58\n",
      "2012-04-11 18:58:53\n",
      "2012-03-15 17:29:59\n",
      "2011-12-26 14:58:48\n",
      "2011-10-14 19:24:29\n",
      "2010-11-06 12:26:25\n",
      "2010-09-21 18:20:34\n",
      "2020-11-14 12:06:38\n",
      "2020-11-03 02:43:11\n",
      "2019-11-23 14:09:01\n",
      "2019-11-18 00:09:17\n",
      "2019-11-17 23:34:13\n",
      "2019-11-17 23:27:29\n",
      "2019-11-17 22:40:37\n",
      "2019-11-17 22:13:22\n",
      "2019-11-17 21:24:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "iterator = 0\n",
    "counter = 0\n",
    "fmt = '%Y-%m-%d %H:%M:%S'\n",
    "for _ in tqdm(df.created_at):\n",
    "    print(_)\n",
    "    \n",
    "    \n",
    "#     df.loc[iterator, 'created_at'] = df.loc[iterator, 'created_at'].replace(' PST', '')\n",
    "#     df.loc[iterator, 'created_at'] = df.loc[iterator, 'created_at'].replace(' PDT', '')\n",
    "#     iterator += 1\n",
    "#     counter += 1\n",
    "# df['created_at'] = pd.to_datetime(df['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded\n"
     ]
    }
   ],
   "source": [
    "def avg_minutes_between_tweets(df):\n",
    "    num_list = []\n",
    "    iterator = 0\n",
    "    for _ in range(len(df)-1):\n",
    "        diff = (df.loc[iterator, 'created_at']) - (df.loc[iterator+1, 'created_at'])\n",
    "        diff_minutes = (diff.days * 24 * 60) + (diff.seconds/60)\n",
    "        if diff_minutes < 0:\n",
    "            diff_minutes = 0\n",
    "        num_list.append(diff_minutes)\n",
    "        iterator += 1\n",
    "    try: avg = sum(num_list) / len(num_list)\n",
    "    except ZeroDivisionError: avg = 0\n",
    "    return float(avg), min(num_list), max(num_list)\n",
    "\n",
    "print('Functions loaded') #Progress Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which file name would you like me to read (minus the suffix)? Saugus_HS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████▍                                                        | 149/541 [00:00<00:00, 1489.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main DataFrame loaded\n",
      "Changing \"created_at\" column to datetime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 541/541 [00:00<00:00, 1490.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created_at column changed\n",
      "DataFrames Loaded\n"
     ]
    }
   ],
   "source": [
    "# ---Establish dataframes---\n",
    "\n",
    "file = input('Which file name would you like me to read (minus the suffix)? ')\n",
    "\n",
    "df = pd.read_csv(file+'.csv')\n",
    "print('Main DataFrame loaded') #Progress Check\n",
    "print('Changing \"created_at\" column to datetime')\n",
    "prep_created_at_column(df, file+'2')\n",
    "print('Created_at column changed') #Progress Check\n",
    "df.to_csv(file+'2.csv')\n",
    "refined_df = pd.DataFrame()\n",
    "\n",
    "print('DataFrames Loaded') #Progress Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username count completed\n"
     ]
    }
   ],
   "source": [
    "#---Processing script---\n",
    "\n",
    "# --- username frequency ---\n",
    "\n",
    "usernames = []\n",
    "for b in df['username']:\n",
    "    usernames.append(b)\n",
    "\n",
    "username_count = dict(Counter(usernames))\n",
    "\n",
    "print('username count completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                              | 8/179 [00:00<00:02, 77.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: stillslippery\n",
      "stillslippery DataFrame established\n",
      "Processing: lacrossesaugus\n",
      "lacrossesaugus DataFrame established\n",
      "Processing: sierraa_meow\n",
      "sierraa_meow DataFrame established\n",
      "Processing: fearlessviviana\n",
      "fearlessviviana DataFrame established\n",
      "Processing: baskinnewhall\n",
      "baskinnewhall DataFrame established\n",
      "Processing: justinnaranjo5\n",
      "justinnaranjo5 DataFrame established\n",
      "Processing: michtait\n",
      "michtait DataFrame established\n",
      "Processing: simonmestas\n",
      "simonmestas DataFrame established\n",
      "Processing: wcedance\n",
      "wcedance DataFrame established\n",
      "Processing: scottspring2\n",
      "scottspring2 DataFrame established\n",
      "Processing: craigass14\n",
      "craigass14 DataFrame established\n",
      "Processing: colettemiller\n",
      "colettemiller DataFrame established\n",
      "Processing: socalirishsport\n",
      "socalirishsport DataFrame established\n",
      "Processing: mattgutmanabc\n",
      "mattgutmanabc DataFrame established\n",
      "Processing: alhenkel\n",
      "alhenkel DataFrame established\n",
      "Processing: abc7marccr\n",
      "abc7marccr DataFrame established\n",
      "Processing: jeffturner\n",
      "jeffturner DataFrame established\n",
      "Processing: ryandrake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▉                                                                  | 33/179 [00:00<00:01, 94.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ryandrake DataFrame established\n",
      "Processing: ispycc\n",
      "ispycc DataFrame established\n",
      "Processing: jeremymalm\n",
      "jeremymalm DataFrame established\n",
      "Processing: davidward\n",
      "davidward DataFrame established\n",
      "Processing: allmymusicsucks\n",
      "allmymusicsucks DataFrame established\n",
      "Processing: huntergirch3\n",
      "huntergirch3 DataFrame established\n",
      "Processing: tammyxmurga\n",
      "tammyxmurga DataFrame established\n",
      "Processing: gavnjules\n",
      "gavnjules DataFrame established\n",
      "Processing: runnerslane\n",
      "runnerslane DataFrame established\n",
      "Processing: 47young1\n",
      "47young1 DataFrame established\n",
      "Processing: pictureman415\n",
      "pictureman415 DataFrame established\n",
      "Processing: barrieeget\n",
      "barrieeget DataFrame established\n",
      "Processing: abc7robhayes\n",
      "abc7robhayes DataFrame established\n",
      "Processing: francislozano7\n",
      "francislozano7 DataFrame established\n",
      "Processing: hansgutknecht\n",
      "hansgutknecht DataFrame established\n",
      "Processing: steveconard\n",
      "steveconard DataFrame established\n",
      "Processing: abelalvarezcu\n",
      "abelalvarezcu DataFrame established\n",
      "Processing: austindave_\n",
      "austindave_ DataFrame established\n",
      "Processing: judijo\n",
      "judijo DataFrame established\n",
      "Processing: chloeestangl\n",
      "chloeestangl DataFrame established\n",
      "Processing: kkeellrr\n",
      "kkeellrr DataFrame established\n",
      "Processing: trustingdragon\n",
      "trustingdragon DataFrame established\n",
      "Processing: katfran\n",
      "katfran DataFrame established\n",
      "Processing: flimjannery\n",
      "flimjannery DataFrame established\n",
      "Processing:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████▊                                                     | 60/179 [00:00<00:01, 111.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " madisonbain_\n",
      "madisonbain_ DataFrame established\n",
      "Processing: bradilady\n",
      "bradilady DataFrame established\n",
      "Processing: jossyboo\n",
      "jossyboo DataFrame established\n",
      "Processing: alemanywarriors\n",
      "alemanywarriors DataFrame established\n",
      "Processing: iamtgcmac3g\n",
      "iamtgcmac3g DataFrame established\n",
      "Processing: osburnmom\n",
      "osburnmom DataFrame established\n",
      "Processing: zfarbs7\n",
      "zfarbs7 DataFrame established\n",
      "Processing: _thir13en\n",
      "_thir13en DataFrame established\n",
      "Processing: howdodeleteme\n",
      "howdodeleteme DataFrame established\n",
      "Processing: sparkles284\n",
      "sparkles284 DataFrame established\n",
      "Processing: ceeduggg\n",
      "ceeduggg DataFrame established\n",
      "Processing: mhfeder\n",
      "mhfeder DataFrame established\n",
      "Processing: erinhalverson6\n",
      "erinhalverson6 DataFrame established\n",
      "Processing: rich_in_saugus\n",
      "rich_in_saugus DataFrame established\n",
      "Processing: wrbaseball\n",
      "wrbaseball DataFrame established\n",
      "Processing: halisapal\n",
      "halisapal DataFrame established\n",
      "Processing: sandyfamill\n",
      "sandyfamill DataFrame established\n",
      "Processing: khtssports\n",
      "khtssports DataFrame established\n",
      "Processing: bi_swamp_thing\n",
      "bi_swamp_thing DataFrame established\n",
      "Processing: coachtooz\n",
      "coachtooz DataFrame established\n",
      "Processing: lakingsicecrew\n",
      "lakingsicecrew DataFrame established\n",
      "Processing: apufotos\n",
      "apufotos DataFrame established\n",
      "Processing: cbslatom\n",
      "cbslatom DataFrame established\n",
      "Processing: royalhighdance\n",
      "royalhighdance DataFrame established\n",
      "Processing: jadamontemarano\n",
      "jadamontemarano DataFrame established\n",
      "Processing: marvinmarvlus\n",
      "marvinmarvlus DataFrame established\n",
      "Processing: skartis\n",
      "skartis DataFrame established\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████                                      | 94/179 [00:00<00:00, 134.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: danieljmcgreevy\n",
      "danieljmcgreevy DataFrame established\n",
      "Processing: emalvarenga10\n",
      "emalvarenga10 DataFrame established\n",
      "Processing: davidkimforca\n",
      "davidkimforca DataFrame established\n",
      "Processing: stevieangeles\n",
      "stevieangeles DataFrame established\n",
      "Processing: galswander\n",
      "galswander DataFrame established\n",
      "Processing: abc7jory\n",
      "abc7jory DataFrame established\n",
      "Processing: ann_bergara\n",
      "ann_bergara DataFrame established\n",
      "Processing: two8ninemedia\n",
      "two8ninemedia DataFrame established\n",
      "Processing: danwelh90\n",
      "danwelh90 DataFrame established\n",
      "Processing: bnahin\n",
      "bnahin DataFrame established\n",
      "Processing: ryanmcpartlin\n",
      "ryanmcpartlin DataFrame established\n",
      "Processing: debmophoto\n",
      "debmophoto DataFrame established\n",
      "Processing: cocobean41\n",
      "cocobean41 DataFrame established\n",
      "Processing: shawniewise7\n",
      "shawniewise7 DataFrame established\n",
      "Processing: abc7joshhaskell\n",
      "abc7joshhaskell DataFrame established\n",
      "Processing: alseibphoto\n",
      "alseibphoto DataFrame established\n",
      "Processing: kylebratzel\n",
      "kylebratzel DataFrame established\n",
      "Processing: princesstochtli\n",
      "princesstochtli DataFrame established\n",
      "Processing: cicada_news\n",
      "cicada_news DataFrame established\n",
      "Processing: greg_cowell\n",
      "greg_cowell DataFrame established\n",
      "Processing: vidcrane\n",
      "vidcrane DataFrame established\n",
      "Processing: chavatweets1\n",
      "chavatweets1 DataFrame established\n",
      "Processing: rickatfox\n",
      "rickatfox DataFrame established\n",
      "Processing: steffdaz\n",
      "steffdaz DataFrame established\n",
      "Processing: donguyenmai\n",
      "donguyenmai DataFrame established\n",
      "Processing: russellwolff\n",
      "russellwolff DataFrame established\n",
      "Processing: kylieejeanne\n",
      "kylieejeanne DataFrame established\n",
      "Processing: ekglizzy\n",
      "ekglizzy DataFrame established\n",
      "Processing: espinozareport\n",
      "espinozareport DataFrame established\n",
      "Processing: frank_i7\n",
      "frank_i7 DataFrame established\n",
      "Processing: savanna_b_news\n",
      "savanna_b_news DataFrame established\n",
      "Processing: teddylnnit\n",
      "teddylnnit DataFrame established\n",
      "Processing: skyelaringrsoll\n",
      "skyelaringrsoll DataFrame established\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████████████████████████████████████████████████▎                     | 130/179 [00:00<00:00, 153.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: alvarezv_\n",
      "alvarezv_ DataFrame established\n",
      "Processing: simsjames\n",
      "simsjames DataFrame established\n",
      "Processing: d_figueroaa\n",
      "d_figueroaa DataFrame established\n",
      "Processing: prettyassleee\n",
      "prettyassleee DataFrame established\n",
      "Processing: rockthebird55\n",
      "rockthebird55 DataFrame established\n",
      "Processing: fredemmerson25\n",
      "fredemmerson25 DataFrame established\n",
      "Processing: taylorbr000ke\n",
      "taylorbr000ke DataFrame established\n",
      "Processing: misstredick_\n",
      "misstredick_ DataFrame established\n",
      "Processing: denicegomez84\n",
      "denicegomez84 DataFrame established\n",
      "Processing: mrsmshandmade\n",
      "mrsmshandmade DataFrame established\n",
      "Processing: saugus_bluecrew\n",
      "saugus_bluecrew DataFrame established\n",
      "Processing: kerrymulbeau\n",
      "kerrymulbeau DataFrame established\n",
      "Processing: jamesnramirez\n",
      "jamesnramirez DataFrame established\n",
      "Processing: ilovemargaritas\n",
      "ilovemargaritas DataFrame established\n",
      "Processing: saugushoops\n",
      "saugushoops DataFrame established\n",
      "Processing: swirlgirlspearl\n",
      "swirlgirlspearl DataFrame established\n",
      "Processing: karenbradder\n",
      "karenbradder DataFrame established\n",
      "Processing: edwards_rach\n",
      "edwards_rach DataFrame established\n",
      "Processing: scottritter12\n",
      "scottritter12 DataFrame established\n",
      "Processing: nat_suneemay\n",
      "nat_suneemay DataFrame established\n",
      "Processing: jetsettergabe\n",
      "jetsettergabe DataFrame established\n",
      "Processing: chrisnaddour\n",
      "chrisnaddour DataFrame established\n",
      "Processing: meghangwine\n",
      "meghangwine DataFrame established\n",
      "Processing: justin_deanda\n",
      "justin_deanda DataFrame established\n",
      "Processing: saugus_vb\n",
      "saugus_vb DataFrame established\n",
      "Processing: mendcryo\n",
      "mendcryo DataFrame established\n",
      "Processing: lorirdunn\n",
      "lorirdunn DataFrame established\n",
      "Processing: timelords_13\n",
      "timelords_13 DataFrame established\n",
      "Processing: toucheole\n",
      "toucheole DataFrame established\n",
      "Processing: aubreyhaffner\n",
      "aubreyhaffner DataFrame established\n",
      "Processing: gofusionngrill\n",
      "gofusionngrill DataFrame established\n",
      "Processing: deloswalton\n",
      "deloswalton DataFrame established\n",
      "Processing: cassiemeissel\n",
      "cassiemeissel DataFrame established\n",
      "Processing: thehund\n",
      "thehund DataFrame established\n",
      "Processing: brooke2385\n",
      "brooke2385 DataFrame established\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████████████▎     | 166/179 [00:01<00:00, 164.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: clarissapetzold\n",
      "clarissapetzold DataFrame established\n",
      "Processing: ninxcachon\n",
      "ninxcachon DataFrame established\n",
      "Processing: sunntanner\n",
      "sunntanner DataFrame established\n",
      "Processing: asap_toby\n",
      "asap_toby DataFrame established\n",
      "Processing: bgmama24\n",
      "bgmama24 DataFrame established\n",
      "Processing: baleyhuggle\n",
      "baleyhuggle DataFrame established\n",
      "Processing: paul_santilli\n",
      "paul_santilli DataFrame established\n",
      "Processing: sheddly22\n",
      "sheddly22 DataFrame established\n",
      "Processing: ssakaboo\n",
      "ssakaboo DataFrame established\n",
      "Processing: therobotmommy\n",
      "therobotmommy DataFrame established\n",
      "Processing: pete6591\n",
      "pete6591 DataFrame established\n",
      "Processing: lance_52\n",
      "lance_52 DataFrame established\n",
      "Processing: sierahollander\n",
      "sierahollander DataFrame established\n",
      "Processing: paulamay12_\n",
      "paulamay12_ DataFrame established\n",
      "Processing: aylamakena\n",
      "aylamakena DataFrame established\n",
      "Processing: laurennnhenryyy\n",
      "laurennnhenryyy DataFrame established\n",
      "Processing: 2quickmynigg20\n",
      "2quickmynigg20 DataFrame established\n",
      "Processing: jsmisko\n",
      "jsmisko DataFrame established\n",
      "Processing: wooviews_\n",
      "wooviews_ DataFrame established\n",
      "Processing: gschink96\n",
      "gschink96 DataFrame established\n",
      "Processing: rosiemanzano\n",
      "rosiemanzano DataFrame established\n",
      "Processing: mikey_wilke\n",
      "mikey_wilke DataFrame established\n",
      "Processing: sortogio\n",
      "sortogio DataFrame established\n",
      "Processing: vrbteach\n",
      "vrbteach DataFrame established\n",
      "Processing: deviousbear\n",
      "deviousbear DataFrame established\n",
      "Processing: paigemarie98\n",
      "paigemarie98 DataFrame established\n",
      "Processing: uclacoachrams\n",
      "uclacoachrams DataFrame established\n",
      "Processing: beckatobes\n",
      "beckatobes DataFrame established\n",
      "Processing: kimmielockhart7\n",
      "kimmielockhart7 DataFrame established\n",
      "Processing: elainanelsonnn\n",
      "elainanelsonnn DataFrame established\n",
      "Processing: nadianoel_\n",
      "nadianoel_ DataFrame established\n",
      "Processing: mmsanett\n",
      "mmsanett DataFrame established\n",
      "Processing:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████████████████████████████████████████| 179/179 [00:01<00:00, 149.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " amberphipps00\n",
      "amberphipps00 DataFrame established\n",
      "Processing: thektanomaly\n",
      "thektanomaly DataFrame established\n",
      "Processing: whitnowwhitning\n",
      "whitnowwhitning DataFrame established\n",
      "Processing: dfgrumpy\n",
      "dfgrumpy DataFrame established\n",
      "Processing: hartindiansfb\n",
      "hartindiansfb DataFrame established\n",
      "Processing: haileybwinslow\n",
      "haileybwinslow DataFrame established\n",
      "Processing: brad_o_williams\n",
      "brad_o_williams DataFrame established\n",
      "Processing: acalagias\n",
      "acalagias DataFrame established\n",
      "Processing: tiedtohope\n",
      "tiedtohope DataFrame established\n",
      "Processing: emilyfiitz\n",
      "emilyfiitz DataFrame established\n",
      "Processing: passthepinot\n",
      "passthepinot DataFrame established\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>total_tweets</th>\n",
       "      <th>total_retweets</th>\n",
       "      <th>hashtag_frequency</th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "      <th>date_range_day_count</th>\n",
       "      <th>mentions</th>\n",
       "      <th>avg_min_between_tweets</th>\n",
       "      <th>min_min_between_tweets</th>\n",
       "      <th>max_min_between_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stillslippery</td>\n",
       "      <td>136.0</td>\n",
       "      <td>{False: 136}</td>\n",
       "      <td>{'': 135, 'saugus': 1, 'shs': 1}</td>\n",
       "      <td>2011-10-14</td>\n",
       "      <td>2018-05-05</td>\n",
       "      <td>2395.0</td>\n",
       "      <td>{'(@': 49}</td>\n",
       "      <td>25545.62</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1061996.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lacrossesaugus</td>\n",
       "      <td>123.0</td>\n",
       "      <td>{False: 123}</td>\n",
       "      <td>{'sauguslax': 116, 'lacrosse': 107, 'saugusath...</td>\n",
       "      <td>2018-06-08</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>669.0</td>\n",
       "      <td>{'@': 118, '@NDSO_Athletics': 1, '@LacrosseSau...</td>\n",
       "      <td>7898.07</td>\n",
       "      <td>0.90</td>\n",
       "      <td>233336.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sierraa_meow</td>\n",
       "      <td>17.0</td>\n",
       "      <td>{False: 17}</td>\n",
       "      <td>{'': 12, 'homecomming': 1, 'weston': 1, 'shake...</td>\n",
       "      <td>2012-05-29</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>155.0</td>\n",
       "      <td>{'@': 17, '@zachgarl': 1, '@shannonwestlake': ...</td>\n",
       "      <td>13955.02</td>\n",
       "      <td>291.62</td>\n",
       "      <td>109233.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fearlessviviana</td>\n",
       "      <td>9.0</td>\n",
       "      <td>{False: 9}</td>\n",
       "      <td>{'': 8, 'fall': 1}</td>\n",
       "      <td>2012-08-27</td>\n",
       "      <td>2013-03-29</td>\n",
       "      <td>214.0</td>\n",
       "      <td>{'@': 9, '@seekmynebula': 1}</td>\n",
       "      <td>38543.61</td>\n",
       "      <td>2626.70</td>\n",
       "      <td>93984.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baskinnewhall</td>\n",
       "      <td>8.0</td>\n",
       "      <td>{False: 8}</td>\n",
       "      <td>{'saugus': 8, 'santaclarita': 8, 'saugushighsc...</td>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>165.0</td>\n",
       "      <td>{'@': 4, '@BaskinNewhall': 4}</td>\n",
       "      <td>33837.98</td>\n",
       "      <td>0.08</td>\n",
       "      <td>112435.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username  total_tweets total_retweets  \\\n",
       "0    stillslippery         136.0   {False: 136}   \n",
       "1   lacrossesaugus         123.0   {False: 123}   \n",
       "2     sierraa_meow          17.0    {False: 17}   \n",
       "3  fearlessviviana           9.0     {False: 9}   \n",
       "4    baskinnewhall           8.0     {False: 8}   \n",
       "\n",
       "                                   hashtag_frequency    min_date    max_date  \\\n",
       "0                   {'': 135, 'saugus': 1, 'shs': 1}  2011-10-14  2018-05-05   \n",
       "1  {'sauguslax': 116, 'lacrosse': 107, 'saugusath...  2018-06-08  2020-04-07   \n",
       "2  {'': 12, 'homecomming': 1, 'weston': 1, 'shake...  2012-05-29  2012-10-31   \n",
       "3                                 {'': 8, 'fall': 1}  2012-08-27  2013-03-29   \n",
       "4  {'saugus': 8, 'santaclarita': 8, 'saugushighsc...  2019-06-21  2019-12-03   \n",
       "\n",
       "   date_range_day_count                                           mentions  \\\n",
       "0                2395.0                                         {'(@': 49}   \n",
       "1                 669.0  {'@': 118, '@NDSO_Athletics': 1, '@LacrosseSau...   \n",
       "2                 155.0  {'@': 17, '@zachgarl': 1, '@shannonwestlake': ...   \n",
       "3                 214.0                       {'@': 9, '@seekmynebula': 1}   \n",
       "4                 165.0                      {'@': 4, '@BaskinNewhall': 4}   \n",
       "\n",
       "   avg_min_between_tweets  min_min_between_tweets  max_min_between_tweets  \n",
       "0                25545.62                    0.18              1061996.80  \n",
       "1                 7898.07                    0.90               233336.23  \n",
       "2                13955.02                  291.62               109233.63  \n",
       "3                38543.61                 2626.70                93984.32  \n",
       "4                33837.98                    0.08               112435.83  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- processing ---\n",
    "iterator = 0\n",
    "for handle in tqdm(sorted(username_count, key=username_count.get, reverse=True)):\n",
    "    print('Processing:', handle) #Progress Check\n",
    "    temp_df = df[df['username'] == handle] #Establishes a temp sorted df of each username encountered\n",
    "    print(handle, 'DataFrame established') #Progress Check\n",
    "    temp_df = temp_df.reset_index(drop=True)\n",
    "    refined_df.loc[iterator, 'username'] = handle\n",
    "    refined_df.loc[iterator, 'total_tweets'] = int(len(temp_df))\n",
    "    refined_df.loc[iterator, 'total_retweets'] = [dict(Counter(list(temp_df['retweet'])))]\n",
    "    refined_df.loc[iterator, 'hashtag_frequency'] = [dict(Counter(hashtags_used_count(handle)).most_common())]\n",
    "    try: min_date, max_date = min_max_date(handle)\n",
    "    except ValueError: continue\n",
    "    refined_df.loc[iterator, 'min_date'] = (min_date)\n",
    "    refined_df.loc[iterator, 'max_date'] = (max_date)\n",
    "    refined_df.loc[iterator, 'date_range_day_count'] = count_days(min_date, max_date)\n",
    "    mentions = [extract_mentions(temp_df)]\n",
    "    refined_df.loc[iterator, 'mentions'] = mentions\n",
    "    try: avg, min_between, max_between = avg_minutes_between_tweets(temp_df)\n",
    "    except ValueError: continue\n",
    "    refined_df.loc[iterator, 'avg_min_between_tweets'] = float(round(Decimal(str(avg)), 2))\n",
    "    refined_df.loc[iterator, 'min_min_between_tweets'] = float(round(Decimal(str(min_between)), 2))\n",
    "    refined_df.loc[iterator, 'max_min_between_tweets'] = float(round(Decimal(str(max_between)), 2))\n",
    "    \n",
    "    iterator += 1\n",
    "    \n",
    "refined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
